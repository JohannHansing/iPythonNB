{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook I will give a shot at implementing a digit recognition NN using the Keras library for python. This notebook is inspired by [Poonam Ligade's notebook](https://www.kaggle.com/poonaml/deep-neural-network-keras-way/notebook/notebook) on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niczfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123ee0eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose example to plot\n",
    "iexample=6\n",
    "\n",
    "# plot example\n",
    "pixels=df_train.iloc[iexample,1:].reshape(28,28)\n",
    "plt.imshow(pixels,cmap='gray')\n",
    "\n",
    "# check example label\n",
    "print('Example label: ',df_train['label'][iexample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Preprocessing image data\n",
    "Here we write a function to renormalize (standardize) the input data (center around zero and divide by variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Note that Keras takes numpy arrays as input!\n",
    "X_total = np.array(df_train.drop([\"label\"],1),dtype=\"f\")#f --> float32\n",
    "y_labels = np.array(df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:4: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n"
     ]
    }
   ],
   "source": [
    "mean_train = X_total.mean(axis=0)\n",
    "var_train = X_total.var(axis=0)\n",
    "def standardize(x):\n",
    "    tmp = (x - mean_train)/var_train\n",
    "    return np.nan_to_num(tmp)\n",
    "X_total = standardize(X_total)\n",
    "print(len(X_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_total[iexample].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10eb28550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLYSFzzAthIXPMC2Ehc8wLeT/AYrLImWN/wqEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1102236d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Re-plot example after standardization\n",
    "pixels=X_total[iexample].reshape(28,28)\n",
    "plt.imshow(pixels,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reshape train and test data, in order to use Keras ImageDataGenerator preprocesser \n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "X_total = X_total.reshape(len(X_total),28,28,1)\n",
    "X_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Changing y_total from continuous label to one-hot vector\n",
    "# My implementation\n",
    "# y_total = np.zeros((len(y_labels),10))\n",
    "# y_total[np.arange(len(y_labels)),y_labels] = 1\n",
    "# works fine, but better use Keras. (In fact checking the Keras source code, it performs almost exactly the same operation)\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_total = to_categorical(y_labels)\n",
    "\n",
    "### Split data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_total, y_total, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 4, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_total[0:5])\n",
    "y_labels[0:5]\n",
    "### Result looks correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next up, I will use Keras to generate a sequental NN for digit recognition. Tutorials can be found on the [Keras website](https://keras.io/getting-started/sequential-model-guide/#examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# inspired from https://elitedatascience.com/keras-tutorial-deep-learning-in-python#step-7\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                184360    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                410       \n",
      "=================================================================\n",
      "Total params: 194,338\n",
      "Trainable params: 194,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary() ## Very useful function to check if the NN does what you expect it to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\r",
      "   1/1181 [..............................] - ETA: 74s - loss: 0.2293 - acc: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/preprocessing/image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (37800, 28, 28, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182/1181 [==============================] - 47s - loss: 0.1008 - acc: 0.9671    \n",
      "Epoch 2/2\n",
      "1182/1181 [==============================] - 47s - loss: 0.1068 - acc: 0.9652    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11bb5b860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Image preprocessing\n",
    "### Sources: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "### https://keras.io/preprocessing/image/\n",
    "### BEST EXPLANATION http://machinelearningmastery.com/image-augmentation-deep-learning-keras/\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 10\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "datagen = image.ImageDataGenerator(\n",
    "        #NOTE: featurewise_center and featurewise_std_normalization are just what I am doing with the standardization function\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        # rotation maybe not helpful here, since the data has normalized orientation\n",
    "        #rotation_range=20,\n",
    "        shear_range=0.1,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4128/4200 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052384199464845765, 0.98523809523809525]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluate on the cross validation set\n",
    "model.evaluate(X_cv, y_cv, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "This CNN gives the best result so far (98,9% accuracy --> 0.989 Kaggle score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for digit identifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      3717\n",
      "          1       1.00      1.00      1.00      4217\n",
      "          2       0.99      0.99      0.99      3787\n",
      "          3       0.99      1.00      0.99      3815\n",
      "          4       0.99      0.99      0.99      3688\n",
      "          5       0.99      0.99      0.99      3464\n",
      "          6       1.00      0.99      0.99      3751\n",
      "          7       0.99      0.99      0.99      3947\n",
      "          8       0.99      0.99      0.99      3674\n",
      "          9       0.98      0.99      0.99      3740\n",
      "\n",
      "avg / total       0.99      0.99      0.99     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### classification report #####\n",
    "predictions_train = model.predict_classes(X_train, verbose=0)\n",
    "y_train_labels = y_train.argmax(axis=-1)\n",
    "print('classification report for digit identifier:\\n',classification_report(predictions_train,y_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3703,    0,    4,    1,    1,    3,    8,    1,    3,    0],\n",
       "       [   0, 4198,    7,    2,    3,    0,    2,    1,    0,    0],\n",
       "       [   1,    2, 3738,    3,    2,    1,    1,    4,    3,    2],\n",
       "       [   1,    1,   12, 3801,    0,   14,    0,    3,    9,    4],\n",
       "       [   1,    4,    3,    0, 3654,    0,    5,    2,    0,    6],\n",
       "       [   0,    0,    1,    5,    1, 3427,   12,    0,   10,    0],\n",
       "       [   4,    0,    0,    0,    3,    6, 3719,    0,    3,    0],\n",
       "       [   1,    8,   17,    0,    7,    2,    0, 3919,    1,    8],\n",
       "       [   0,    2,    4,    1,    0,    4,    4,    0, 3637,    8],\n",
       "       [   6,    2,    1,    2,   17,    7,    0,   17,    8, 3712]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "##### CONFUSION MATRIX #####\n",
    "############################\n",
    "# https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "# die confusion matrix zeigt an, wie die labels des training sets klassifiziert wurden. \n",
    "# Zum Beispiel wurde '0' acht mal als '6' falsch klassifiziert. Interessanterweise, nie als '9'\n",
    "# Man sieht, dass '9' sehr oft mit '4' oder '7' verwechselt wird (17 Mal)\n",
    "confusion_matrix(y_train_labels, predictions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Using a larger fully connected layer (100 nodes) leads to overfitting with a training accuracy of 99.1%, but a test score of 98.2%, i.e. less than the 98.4% which I got with less hidden nodes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model weights...\n",
    "model.save('CNNmodel_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try more convolution layers with some stride>1 convolutional layers instead of pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/c/digit-recognizer/discussion/23999\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ZeroPadding2D(5, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(30, 9, activation='relu'))\n",
    "model.add(ZeroPadding2D(1, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(40, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D(2, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(40, 5, activation='relu',strides=(2, 2)))\n",
    "model.add(ZeroPadding2D(2, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(40, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D(2, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(20, 5, activation='relu',strides=(2, 2)))\n",
    "model.add(ZeroPadding2D(1, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(20, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D(1, input_shape=X_train.shape[1:]))\n",
    "model.add(Convolution2D(20, 5, activation='relu',strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam',\n",
    "              #optimizer=RMSprop(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/preprocessing/image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (32000, 28, 28, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 193s - loss: 0.1372 - acc: 0.9663   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c59ef60>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "datagen = image.ImageDataGenerator(\n",
    "        #NOTE: featurewise_center and featurewise_std_normalization are just what I am doing with the standardization function\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        #rescale=1./255,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        # added a little rotation\n",
    "        rotation_range=10,\n",
    "        shear_range=0.1,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 17s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.060812906496194044, 0.98550000000000004]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_cv, y_cv, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 17s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.073354644408593225, 0.98262499999999997]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_cv, y_cv, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conlcusion:\n",
    "This takes much longer to train but it does not lead to a much improved score on the Kaggle test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other CNN - more filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://elitedatascience.com/keras-tutorial-deep-learning-in-python#step-7\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=5, activation='relu', input_shape=X_train.shape[1:]))\n",
    "## Here, I added more filters\n",
    "model2.add(Conv2D(64, kernel_size=5, activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "## Here, I add another convoluational layer\n",
    "model2.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(40, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Nadam',\n",
    "              #optimizer=RMSprop(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\r",
      "   1/1181 [..............................] - ETA: 136s - loss: 0.0459 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/preprocessing/image.py:648: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (37800, 28, 28, 1) (1 channels).\n",
      "  ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 667/1181 [===============>..............] - ETA: 46s - loss: 0.1700 - acc: 0.9516"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "epochs = 10\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "datagen = image.ImageDataGenerator(\n",
    "        #NOTE: featurewise_center and featurewise_std_normalization are just what I am doing with the standardization function\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        #rescale=1./255,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        # rotation is not helpful here, since the data has normalized orientation\n",
    "        #rotation_range=20,\n",
    "        shear_range=0.1,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model2.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(X_train) / batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "- Try active learning for digit recognition: http://scikit-learn.org/stable/auto_examples/semi_supervised/plot_label_propagation_digits_active_learning.html#sphx-glr-auto-examples-semi-supervised-plot-label-propagation-digits-active-learning-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/ipykernel/__main__.py:4: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(df_test,dtype=\"f\")\n",
    "print(X_test.dtype)\n",
    "X_test = standardize(X_test)\n",
    "X_test = X_test.reshape(len(X_test),28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"pred_sub.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
